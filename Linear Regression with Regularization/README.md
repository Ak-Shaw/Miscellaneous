# Linear Regression with Regularization

## Introduction

**Linear Regression** is the most simple, yet the most important statistical technique to estimate the relationship between the independant and the dependant features. It aims at predicting a **continuous variable** like house prices, sales of a company etc.<br>

In this micro task, we will take a look at linear regression by solving a problem of **predicting the price of a house given its attributes or features.**

## Prerequisites

You should have a basic knowledge of **python** and **pandas**.

## Activities

### Activity 1 - Understanding Linear Regression

Let us begin with understanding the basics of linear regression.
> Refer to Activity 1 - Understanding Linear Regression.ipynb

### Activity 2 - Assumptions of Linear Regression

So, now you know the basics of linear regression. But there are some assumptions associated with it which the data needs to satisfy for Linear Regression. Let us now have a look at that.
> Refer to Activity 2 - Assumptions of Linear Regression.ipynb

### Activity 3 - Ridge, Lasso and ElasticNet Regression

These are 3 different types of regression techniques which provides different regularization techniques to prevent overfitting. Let us learn more about them in detail.
> Refer to Activity 3 - Ridge, Lasso and ElasticNet Regression.ipynb

## Summary

Now, you know the basics of Linear Regression along with its assumptions and different regularized variations of it.

## References

1. Dataset: [https://www.kaggle.com/shree1992/housedata](https://www.kaggle.com/shree1992/housedata)