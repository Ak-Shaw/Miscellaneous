{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "Also known as L2 Regularization.\n",
    "\n",
    "The most basic and only difference between a ridge and a linear regression is in their cost function.\n",
    "\n",
    "Cost Function of Ridge Regression = Cost of Linear Regression + lambda * sum of sqaured coefficients\n",
    "\n",
    "Here, lambda is a parameter which is evaluated using cross validation. This term lambda is referred to as **alpha** in the scikit-learn API.\n",
    "\n",
    "Ridge Regression is used to prevent overfitting and hence resulting in a more generalised model.\n",
    "\n",
    "When lambda= 0, Ridge regression behaves as Linear Regression\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Let's look at its implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:  987608046392.3278\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#load the data\n",
    "data = pd.read_csv('../../data/data_cleaned.csv')\n",
    "\n",
    "#seperate dependant and independant variables\n",
    "X = data.drop('price', axis= 1)\n",
    "y = data.price\n",
    "\n",
    "#split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)\n",
    "\n",
    "#initialize the model\n",
    "ridge = Ridge(alpha= 1000) #randomly chosen value of alpha\n",
    "\n",
    "#fit the model to training data\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "#evaluate the model on test data\n",
    "ridge_error = mean_squared_error(y_test, ridge.predict(X_test))\n",
    "print(\"Test Error: \", ridge_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "1. https://www.youtube.com/watch?v=Q81RR3yKn30&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=19\n",
    "\n",
    "\n",
    "# Lasso Regression\n",
    "\n",
    "Also known as L1 Regularization.\n",
    "\n",
    "Lasso Regression is also similar to Linear Regression with a slight modification in its cost function.\n",
    "\n",
    "Cost Function of Lasso Regression = Cost Function of Linear Regression + lambda * sum of absolute values of coefficients.\n",
    "\n",
    "Lambda is evaluated using cross validation. Here also, it is referred to as **alpha** in scikit-learn API.\n",
    "\n",
    "Similar to Ridge regression, it is also used to prevent overfitting but due to the nature of its cost function, it is also used as a feature selector. This is because while training the model, it reduces the coefficients of unimportant variables to zero. On the other hand, ridge regression reduces the coefficients close to zero but not exactly zero.\n",
    "\n",
    "When lambda= 0, Lasso regression behaves similar to Ridge Regression.\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:  987938117803.2545\n"
     ]
    }
   ],
   "source": [
    "#import the model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#initialize the model\n",
    "lasso = Lasso(alpha= 1100) #random value of alpha\n",
    "\n",
    "#fit the model on training data\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "#evaluate the model on test data\n",
    "lasso_error = mean_squared_error(y_test, lasso.predict(X_test))\n",
    "print(\"Test Error: \", lasso_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "1. https://www.youtube.com/watch?v=NGf0voTMlcs&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=20\n",
    "2. https://www.youtube.com/watch?v=NGf0voTMlcs&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=21\n",
    "\n",
    "\n",
    "# ElasticNet Regression\n",
    "\n",
    "This regression is a hybrid of Ridge and Lasso Regression thus combining the strengths of both of the regularization techniques.\n",
    "\n",
    "Cost Function of ElasticNet Regression = Cost Function of Linear Regression + lambda1 * sum of squared coefficients + lambda2 * sum of absolute values of coefficients.\n",
    "\n",
    "The values lambda1 and lambda2 can be found using cross validation.\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:  987605035501.2186\n"
     ]
    }
   ],
   "source": [
    "#import the model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "#initialize the model\n",
    "elasticnet = ElasticNet(l1_ratio= 0.7)\n",
    "\n",
    "#fit the model on training data\n",
    "elasticnet.fit(X_train, y_train)\n",
    "\n",
    "#evaluate the model on test data\n",
    "elastic_error = mean_squared_error(y_test, elasticnet.predict(X_test))\n",
    "print(\"Test Error: \", elastic_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "1. https://www.youtube.com/watch?v=NGf0voTMlcs&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=22"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
