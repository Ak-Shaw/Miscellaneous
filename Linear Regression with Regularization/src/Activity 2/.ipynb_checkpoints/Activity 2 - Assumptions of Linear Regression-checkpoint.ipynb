{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions of Linear Regression\n",
    "\n",
    "Previously, we learned to apply linear regression on a given dataset. But it is important to note that Linear Regression have some assumptions related to the data on which it is applied and if they are not followed, it can affect its performance. These assumptions are:\n",
    "\n",
    "1. There should be a linear relationship between the dependant and the independant features.\n",
    "2. There should be no auto-correlation. This means that the error terms should not be correlated.\n",
    "3. The variance of error terms should be equal.\n",
    "4. There should be no multi-collinearity. This means that no 2 independant features should be highly correlated.\n",
    "5. The errors should be normally distributed.\n",
    "\n",
    "Lets check these assumptions on the model which we have trained in the previous activity.\n",
    "\n",
    "## Loading the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#load the data\n",
    "\n",
    "\n",
    "#seperating dependant and independant features\n",
    "\n",
    "\n",
    "#splitting data into training and test sets\n",
    "\n",
    "\n",
    "#instantiate a model\n",
    "\n",
    "\n",
    "#fit the model to training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "data = pd.read_csv('../../data/data_cleaned.csv')\n",
    "\n",
    "X = data.drop('price', axis= 1)\n",
    "y = data.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42, shuffle= True)\n",
    "    \n",
    "model = LinearRegression()\n",
    "    \n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the model. Lets calculate the residuals first.\n",
    "\n",
    "## Calculate residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe to store residuals\n",
    "result = pd.DataFrame({'Actual': y_test, 'Predicted': model.predict(X_test)})\n",
    "result.reset_index(drop= True, inplace= True) #reset indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make a new column **residuals** by subtracting *Predicted* value from *Actual* values\n",
    "* display top 5 rows of the **result** dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a new column residuals\n",
    "\n",
    "#display top 5 rows of the result dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "result['residuals'] = result.Actual - result.Predicted\n",
    "    \n",
    "result.head()\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the variance and correlation of error terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #importing libraries for plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the residuals\n",
    "plt.scatter(range(len(y_test)), result.residuals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that apart from 3-4 points, the spread of error terms is constant. Hence we can conclude that the variance is constant.\n",
    "Also, there is no specific pattern in the error terms. They are randomly distributed. So, there is no correlation among them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Distribution of Residuals\n",
    "\n",
    "* draw a histogram of residuals from result dataframe using 300 as the number of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "plt.hist(result.residuals, bins= 300)\n",
    "plt.show()\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph it can be concluded that the error terms are normally distributed. The unusually high peak to the curve is caused by the outliers that were pointed out in the first activity. To confirm the distribution, we can also plot a qq plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Multi-Collinearity\n",
    "\n",
    "To check for multi-collinearity, we can find **Variance Inflation Factor** of all the columns. If for any feature, its value is above 5, we can conclude that the feature is correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Variance_inflation_Factor funtion from the Statsmodels\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Calculating VIF for every column (only works for the not Catagorical)\n",
    "VIF = pd.Series([variance_inflation_factor(data.values, i) for i in range(data.shape[1])], index =data.columns)\n",
    "VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 features having VIF greater than 5. We can remove the 2 features having the higher values. So, none of the features will be correlated and hence multi-collinearity can be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This is how we can check the assumptions of Linear Regression and see if everything follows.\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "1. VIF : https://www.analyticsvidhya.com/blog/2020/03/what-is-multicollinearity/\n",
    "2. Assumptions in detail: https://www.analyticsvidhya.com/blog/2016/07/deeper-regression-analysis-assumptions-plots-solutions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
